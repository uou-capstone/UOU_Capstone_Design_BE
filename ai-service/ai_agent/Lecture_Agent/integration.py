import sys
import asyncio
import time
import re
from typing import List, Tuple, Dict, Any, Optional
from ai_agent import PdfAnalysis, MainLectureAgent, MainQandAAgent

pdf_analysis_main = PdfAnalysis.main
pdf_analysis_only = PdfAnalysis.analyze_only
pdf_split_single_chapter = PdfAnalysis.split_single_chapter
lecture_agent_main = MainLectureAgent.main
qa_agent_main = MainQandAAgent.main


def print_streaming(text: str, delay: float = 0.1):
    """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ë“¯ì´ ì¶œë ¥"""
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
    sentences = re.split(r'([.!?]\s+|[.!?]$|\n)', text)
    
    for i in range(0, len(sentences), 2):
        if i < len(sentences):
            sentence = sentences[i]
            if i + 1 < len(sentences):
                sentence += sentences[i + 1]
            
            print(sentence, end='', flush=True)
            time.sleep(delay)
    
    print()  # ë§ˆì§€ë§‰ ì¤„ë°”ê¿ˆ


def extract_questions(text: str) -> List[Tuple[int, int, str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ [ì§ˆë¬¸] [/ì§ˆë¬¸] í† í°ì„ ì°¾ì•„ ìœ„ì¹˜ì™€ ì§ˆë¬¸ ë‚´ìš©ì„ ë°˜í™˜"""
    pattern = r'\[ì§ˆë¬¸\](.*?)\[/ì§ˆë¬¸\]'
    questions = []
    
    for match in re.finditer(pattern, text, re.DOTALL):
        start_pos = match.start()
        end_pos = match.end()
        question_content = match.group(1).strip()
        questions.append((start_pos, end_pos, question_content))
    
    return questions


def build_segments_from_explanation(
    explanation: str,
    prefix: str = ""
) -> Tuple[List[Dict[str, Any]], Dict[str, Dict[str, Any]]]:
    """
    ê°•ì˜ ì„¤ëª…ë¬¸ì„ ìŠ¤í¬ë¦½íŠ¸/ì§ˆë¬¸ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¦¬í•œë‹¤.
    """
    questions = extract_questions(explanation)
    segments: List[Dict[str, Any]] = []
    question_meta: Dict[str, Dict[str, Any]] = {}

    if not questions:
        stripped = explanation.strip()
        if stripped:
            segments.append({"type": "script", "content": stripped})
        return segments, question_meta

    current_pos = 0
    for idx, (start_pos, end_pos, question_content) in enumerate(questions):
        before_question = explanation[current_pos:start_pos]
        if before_question.strip():
            segments.append({"type": "script", "content": before_question.strip()})

        question_id = f"{prefix}q-{idx}" if prefix else f"q-{idx}"
        cleaned_question = question_content.strip()
        segments.append({
            "type": "question",
            "questionId": question_id,
            "question": cleaned_question
        })
        question_meta[question_id] = {
            "question": cleaned_question,
            "questionIndex": idx
        }
        current_pos = end_pos

    remaining = explanation[current_pos:]
    if remaining.strip():
        segments.append({"type": "script", "content": remaining.strip()})

    return segments, question_meta


def process_explanation_with_qa(explanation: str, chapter_title: str, pdf_path: str):
    """ì„¤ëª…ë¬¸ì„ ì²˜ë¦¬í•˜ë©´ì„œ ì§ˆë¬¸ì´ ë‚˜ì˜¤ë©´ Q&A ì—ì´ì „íŠ¸ë¥¼ í˜¸ì¶œ"""
    questions = extract_questions(explanation)
    
    if not questions:
        # ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ ì „ì²´ ì¶œë ¥
        print_streaming(explanation)
        return
    
    # ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš° êµ¬ê°„ë³„ë¡œ ì²˜ë¦¬
    current_pos = 0
    
    for start_pos, end_pos, question_content in questions:
        # ì§ˆë¬¸ ì´ì „ ë¶€ë¶„ ì¶œë ¥
        before_question = explanation[current_pos:start_pos]
        if before_question.strip():
            print_streaming(before_question)
        
        # ì§ˆë¬¸ ì¶œë ¥
        print("\n" + "="*60)
        print(f"[ì§ˆë¬¸]")
        print(question_content)
        print("="*60)
        
        # ì‚¬ìš©ì ë‹µë³€ ë°›ê¸°
        user_answer = input("\në‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        print("\n")
        
        # Q&A ì—ì´ì „íŠ¸ í˜¸ì¶œ
        print("ë‹µë³€ì„ ë¶„ì„í•˜ê³  ë³´ì¶© ì„¤ëª…ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n")
        supplementary_explanation = qa_agent_main([
            (question_content, user_answer),
            pdf_path
        ])
        
        # ë³´ì¶© ì„¤ëª… ì¶œë ¥
        print("\n" + "="*60)
        print("[ë³´ì¶© ì„¤ëª…]")
        print("="*60 + "\n")
        print_streaming(supplementary_explanation)
        print("\n" + "="*60 + "\n")
        
        current_pos = end_pos
    
    # ë§ˆì§€ë§‰ ì§ˆë¬¸ ì´í›„ ë‚¨ì€ ë¶€ë¶„ ì¶œë ¥
    remaining = explanation[current_pos:]
    if remaining.strip():
        print_streaming(remaining)


async def run_lecture_agent(chapter_title: str, pdf_path: str) -> Dict[str, str]:
    """ë¹„ë™ê¸°ë¡œ ê°•ì˜ ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰"""
    return await asyncio.to_thread(lecture_agent_main, chapter_title, pdf_path)


async def run_all_lecture_agents(chapters_info: List[Tuple[str, str]]) -> List[Dict[str, str]]:
    """ëª¨ë“  ì±•í„°ì— ëŒ€í•´ ê°•ì˜ ì—ì´ì „íŠ¸ë¥¼ ë™ì‹œì— ì‹¤í–‰"""
    tasks = []
    for chapter_title, pdf_path in chapters_info:
        task = run_lecture_agent(chapter_title, pdf_path)
        tasks.append(task)
    
    # ìˆœì„œë¥¼ ìœ ì§€í•˜ë©´ì„œ ë™ì‹œ ì‹¤í–‰
    results = await asyncio.gather(*tasks)
    return results


def prepare_lecture_content(pdf_path: str) -> Dict[str, Any]:
    """
    ì§ˆë¬¸ ì¸í„°ë™ì…˜ì„ ì§€ì›í•˜ê¸° ìœ„í•´ ì±•í„°ë³„ ìŠ¤í¬ë¦½íŠ¸/ì§ˆë¬¸ êµ¬ì¡°ë¥¼ ìƒì„±í•œë‹¤.
    """
    chapters_info = pdf_analysis_main(pdf_path)
    lecture_results = asyncio.run(run_all_lecture_agents(chapters_info))

    structured_chapters = []
    for chapter_idx, ((chapter_title, chapter_pdf), lecture_dict) in enumerate(zip(chapters_info, lecture_results)):
        explanation = lecture_dict.get(chapter_title, "")
        segments, question_meta = build_segments_from_explanation(
            explanation,
            prefix=f"c{chapter_idx}-"
        )
        structured_chapters.append({
            "chapterTitle": chapter_title,
            "pdfPath": chapter_pdf,
            "segments": segments,
            "questions": question_meta
        })

    return {
        "chapters": structured_chapters
    }


def generate_supplementary_explanation(question: str, answer: str, pdf_path: str) -> Dict[str, Any]:
    """
    ì‚¬ìš©ì ë‹µë³€ì„ ë°›ì•„ Q&A ì—ì´ì „íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³ ,
    ë³´ì¶© ì„¤ëª…/í‰ê°€ ê²°ê³¼ ë“± êµ¬ì¡°í™”ëœ ì •ë³´ë¥¼ ë°˜í™˜í•œë‹¤.
    """
    result = qa_agent_main([
        (question, answer),
        pdf_path
    ])

    # êµ¬ë²„ì „ í˜¸í™˜: ë¬¸ìì—´ë§Œ ë°˜í™˜ëœ ê²½ìš° ìµœì†Œí•œì˜ êµ¬ì¡°ë¡œ ê°ì‹¼ë‹¤.
    if isinstance(result, str):
        return {
            "supplementary_explanation": result,
            "validation_result": "",
            "concept_queue": [],
            "current_concept_index": 0,
            "bad_mode_history": [],
            "state": "GOOD",
            "needs_follow_up": False
        }

    return result


# ==================== ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œìš© í•¨ìˆ˜ (ìƒˆë¡œ ì¶”ê°€) ====================

def initialize_lecture(pdf_path: str) -> Tuple[List[Dict[str, Any]], str]:
    """
    PDFë¥¼ ë¶„ì„í•˜ì—¬ ì±•í„° ì •ë³´ë§Œ ë°˜í™˜ (ê°•ì˜ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ)
    
    Args:
        pdf_path (str): PDF íŒŒì¼ ê²½ë¡œ
    
    Returns:
        Tuple[List[Dict], str]: (chapters_info, pdf_path)
            chapters_info: [{"chapter_title": str, "start_page": int, "end_page": int}, ...]
            pdf_path: ì›ë³¸ PDF ê²½ë¡œ (ê·¸ëŒ€ë¡œ ë°˜í™˜)
    """
    chapters_info = pdf_analysis_only(pdf_path)
    return chapters_info, pdf_path


def generate_single_chapter(
    pdf_path: str,
    chapter_info: Dict[str, Any],
    chapter_index: int = 0
) -> Dict[str, Any]:
    """
    í•˜ë‚˜ì˜ ì±•í„°ì— ëŒ€í•´ì„œë§Œ ê°•ì˜ë¥¼ ìƒì„±
    
    Args:
        pdf_path (str): ì›ë³¸ PDF íŒŒì¼ ê²½ë¡œ
        chapter_info (Dict): {"chapter_title": str, "start_page": int, "end_page": int}
        chapter_index (int): ì±•í„° ì¸ë±ìŠ¤
    
    Returns:
        Dict: {
            "chapterTitle": str,
            "pdfPath": str,  # ë¶„í• ëœ ì±•í„° PDF ê²½ë¡œ
            "segments": List[Dict],  # [{"type": "script", "content": "..."}, ...]
            "questions": Dict  # {"q-0": {"question": "...", "questionIndex": 0}}
        }
    """
    # 1. íŠ¹ì • ì±•í„°ë§Œ PDFì—ì„œ ì¶”ì¶œ
    chapter_pdf_path = pdf_split_single_chapter(pdf_path, chapter_info, chapter_index)
    
    # 2. ê°•ì˜ ìƒì„±
    chapter_title = chapter_info["chapter_title"]
    lecture_result = lecture_agent_main(chapter_title, chapter_pdf_path)
    explanation = lecture_result.get(chapter_title, "")
    
    # 3. ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¦¬ (ì§ˆë¬¸ íŒŒì‹± í¬í•¨)
    segments, question_meta = build_segments_from_explanation(
        explanation,
        prefix=f"c{chapter_index}-"
    )
    
    return {
        "chapterTitle": chapter_title,
        "pdfPath": chapter_pdf_path,  # ë¶„í• ëœ ì±•í„° PDF ê²½ë¡œ
        "segments": segments,
        "questions": question_meta
    }


def get_next_segment(
    chapter_data: Dict[str, Any],
    current_segment_index: int
) -> Tuple[Optional[Dict], int]:
    """
    ì±•í„° ë°ì´í„°ì—ì„œ ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ í•˜ë‚˜ë§Œ ë°˜í™˜
    
    Args:
        chapter_data (Dict): generate_single_chapterì˜ ê²°ê³¼
        current_segment_index (int): í˜„ì¬ ì½ì€ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤
    
    Returns:
        Tuple[Optional[Dict], int]: (segment, next_index) ë˜ëŠ” (None, -1) if ì±•í„° ë
            segment: {"type": "script"|"question", "content"|"question": str, "questionId": str}
            next_index: ë‹¤ìŒ ì„¸ê·¸ë¨¼íŠ¸ ì¸ë±ìŠ¤ (-1ì´ë©´ ì±•í„° ë)
    """
    segments = chapter_data.get("segments", [])
    
    if current_segment_index >= len(segments):
        return None, -1  # ì±•í„° ë
    
    segment = segments[current_segment_index]
    return segment, current_segment_index + 1


def main(pdf_path: str, skip_qa: bool = False, cancellation_callback=None):
    """
    í†µí•© ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ ë©”ì¸ í•¨ìˆ˜
    
    Args:
        pdf_path (str): ë¶„ì„í•  PDF íŒŒì¼ì˜ ê²½ë¡œ
        skip_qa (bool): Q&A ì²˜ë¦¬ ê±´ë„ˆë›°ê¸° (API í˜¸ì¶œ ì‹œ True)
        cancellation_callback (Callable): í˜¸ì¶œ ì‹œ ì·¨ì†Œ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  ì˜ˆì™¸ë¥¼ ë˜ì§€ëŠ” í•¨ìˆ˜ (Optional)
    
    Returns:
        Tuple[List[Tuple[str, str]], List[Dict[str, str]]]: (chapters_info, lecture_results)
    """
    import traceback
    
    print("="*60)
    print("êµìœ¡ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‹œì‘í•©ë‹ˆë‹¤")
    print("="*60 + "\n")
    
    # ì‹œì‘ ì „ ì·¨ì†Œ ì²´í¬
    if cancellation_callback: cancellation_callback()

    # 1. PDF ë¶„ì„ ë° ì±•í„°ë³„ ë¶„í• 
    print("ğŸ“„ PDF íŒŒì¼ì„ ë¶„ì„í•˜ê³  ì±•í„°ë³„ë¡œ ë¶„í• í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n")
    try:
        chapters_info = pdf_analysis_main(pdf_path)
    except Exception as e:
        print(f"[ERROR] PDF ë¶„ì„ ì¤‘ ì—ëŸ¬ ë°œìƒ: {type(e).__name__}: {str(e)}")
        traceback.print_exc()
        raise
    
    # ë¶„ì„ í›„ ì·¨ì†Œ ì²´í¬
    if cancellation_callback: cancellation_callback()

    print(f"ì´ {len(chapters_info)}ê°œì˜ ì±•í„°ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\n")
    for i, (title, path) in enumerate(chapters_info, 1):
        print(f"  {i}. {title}")
    print("\n")
    
    # 2. ëª¨ë“  ì±•í„°ì— ëŒ€í•´ ë™ì‹œì— ê°•ì˜ ì—ì´ì „íŠ¸ í˜¸ì¶œ
    print("ğŸ“ ê° ì±•í„°ì— ëŒ€í•œ ê°•ì˜ ì„¤ëª…ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...\n")
    
    # ì›ë˜ëŠ” asyncio.run(run_all_lecture_agents(chapters_info)) ì˜€ìœ¼ë‚˜
    # ì·¨ì†Œ ì²´í¬ë¥¼ ìœ„í•´ ì—¬ê¸°ì„œë„ ì§ì ‘ í•¸ë“¤ë§í•˜ê±°ë‚˜ run_all_lecture_agents ë‚´ë¶€ë¥¼ ê³ ì³ì•¼ í•¨.
    # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì‹¤í–‰ ì „í›„ì—ë§Œ ì²´í¬.
    # ë” ì •êµí•œ ì œì–´ê°€ í•„ìš”í•˜ë©´ run_all_lecture_agents ë‚´ë¶€ ë£¨í”„ì—ë„ cancellation_callbackì„ ë„£ì–´ì•¼ í•¨.
    
    # ì·¨ì†Œ ì²´í¬
    if cancellation_callback: cancellation_callback()

    lecture_results = asyncio.run(run_all_lecture_agents(chapters_info))
    
    # ì‹¤í–‰ í›„ ì·¨ì†Œ ì²´í¬
    if cancellation_callback: cancellation_callback()

    print("ëª¨ë“  ê°•ì˜ ì„¤ëª… ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n")
    print("="*60 + "\n")
    
    # 3. Q&A ì²˜ë¦¬ (skip_qaê°€ Falseì¸ ê²½ìš°ì—ë§Œ)
    if not skip_qa:
        # ìˆœì„œëŒ€ë¡œ ê°•ì˜ ì§„í–‰
        for i, ((chapter_title, pdf_path), lecture_dict) in enumerate(zip(chapters_info, lecture_results), 1):
            # ë£¨í”„ë§ˆë‹¤ ì·¨ì†Œ ì²´í¬
            if cancellation_callback: cancellation_callback()

            print("\n" + "="*60)
            print(f"ğŸ“š Chapter {i}: {chapter_title}")
            print("="*60 + "\n")
            
            explanation = lecture_dict[chapter_title]
            
            # ì„¤ëª…ë¬¸ì„ ì²˜ë¦¬í•˜ë©´ì„œ ì§ˆë¬¸ì´ ë‚˜ì˜¤ë©´ Q&A ì§„í–‰
            process_explanation_with_qa(explanation, chapter_title, pdf_path)
            
            # ë‹¤ìŒ ì±•í„°ë¡œ ë„˜ì–´ê°€ê¸° ì „ êµ¬ë¶„ì„ 
            if i < len(chapters_info):
                print("\n" + "="*60)
                print("ë‹¤ìŒ ì±•í„°ë¡œ ì´ë™í•©ë‹ˆë‹¤...")
                print("="*60 + "\n")
                time.sleep(1)
        
        # 4. ëª¨ë“  ê°•ì˜ ì™„ë£Œ
        print("\n" + "="*60)
        print("ëª¨ë“  ê°•ì˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*60)
    
    # ê²°ê³¼ ë°˜í™˜ (API í˜¸ì¶œ ì‹œ ì‚¬ìš©)
    return chapters_info, lecture_results


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ì‚¬ìš©ë²•: python integration.py <PDF íŒŒì¼ ê²½ë¡œ>")
        print("ì˜ˆì‹œ: python integration.py /Users/jhkim/Desktop/Edu_Agent/02-SW-Process.pdf")
        sys.exit(1)
    
    pdf_path = sys.argv[1]
    
    try:
        main(pdf_path)
    except FileNotFoundError as e:
        print(f"âŒ ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

